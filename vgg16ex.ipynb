{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding tf.dataset and TFDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating tf.dataset wit tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X=tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us load the mnist as a tf.dataset from the TFDS project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(\"mnist\",as_supervised=True)\n",
    "train_dataset, test_dataset = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_dataset.take(2):\n",
    "    print(type(item))\n",
    "    images,labels=item\n",
    "    #images = item[\"image\"]\n",
    "    #labels = item[\"label\"]\n",
    "    print(type(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a function that resizes the data\n",
    "def resize_data(x,y):\n",
    "  x = tf.image.resize(x, (224, 224))\n",
    "  return x, y \n",
    "# Apply the resize function to the dataset using map\n",
    "resized_dataset = train_dataset.map(resize_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for item in resized_dataset.take(2):\n",
    "    x,y=item\n",
    "    plt.figure()\n",
    "    plt.imshow(x),plt.title(np.array(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try now with the tf_flowers dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(\"tf_flowers\",as_supervised=True)\n",
    "train_dataset = dataset[\"train\"]\n",
    "def resize_data(x,y):\n",
    "  x = tf.image.resize(x, (224, 224))\n",
    "  return x, y \n",
    "resized_dataset = train_dataset.map(resize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in resized_dataset.take(2):\n",
    "    x,y=item\n",
    "    print(x.shape)\n",
    "    plt.figure()\n",
    "    plt.imshow(x),plt.title(np.array(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done with the tfds.builder but it does not take the as_supervised=True parameter\n",
    "That forces us to use the 'image' 'label' keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Download the Imagenet dataset\n",
    "imagenet_builder = tfds.builder(\"tf_flowers\")\n",
    "imagenet_builder.download_and_prepare()\n",
    "\n",
    "# Load the Imagenet dataset as a `tf.data.Dataset` object\n",
    "imagenet_dataset = imagenet_builder.as_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = imagenet_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert isinstance(train_dataset,tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x=train_dataset.take(1).as_numpy_iterator().next()\n",
    "plt.imshow(x['image'])\n",
    "plt.title(x['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the VGG16 model with weights pre-trained on ImageNet\n",
    "base_model = VGG16(weights='imagenet',include_top=False)\n",
    "base_model.output.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(1, activation=\"softmax\")(avg)\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_dataset = train_dataset.map(resize_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in resized_dataset.batch(32).take(2):\n",
    "    x,y=item\n",
    "    print(x.shape)\n",
    "    model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset that produces batches of data\n",
    "batch_size = 32\n",
    "dataset = resized_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator from the dataset\n",
    "iterator = dataset.__iter__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iterator.get_next()\n",
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "  while True:\n",
    "    try:\n",
    "      # Get the next batch of data from the iterator\n",
    "      batch = iterator.get_next()\n",
    "      # Extract the input and output elements from the batch\n",
    "      x, y = batch\n",
    "      x=resize(x,(224,224))\n",
    "      yield (x, y)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      # Reset the iterator when the dataset is exhausted\n",
    "      iterator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the generator as the input to model.fit\n",
    "model.fit(generator(), epochs=10, steps_per_epoch=len(resized_dataset) // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load some data to use for training or evaluation\n",
    "x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Use the model to make predictions on new data\n",
    "predictions = model.predict(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up the ImageDataGenerator to load and preprocess the image data\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load the data from a directory of images\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the VGG16 model with weights pre-trained on ImageNet\n",
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "# Compile the model with a Adam optimizer and a categorical cross-entropy loss function\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit_generator(train_generator, epochs=10)\n",
    "\n",
    "# Load the validation data in a similar way\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    'data/validation',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "scores = model.evaluate_generator(validation_generator)\n",
    "\n",
    "# Use the model to make predictions on new data\n",
    "x_new = load_new_data()\n",
    "predictions = model.predict(x_new)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50e0cab8bd62756c7fc66a63f77f1d7a5658785ded0a9e3406fe8e8350515108"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
